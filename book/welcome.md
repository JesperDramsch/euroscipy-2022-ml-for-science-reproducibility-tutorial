# Increase citations, ease review & foster collaboration

[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/JesperDramsch/ml-for-science-reproducibility-tutorial/HEAD) 
[![](https://img.shields.io/github/stars/jesperdramsch/ml-for-science-reproducibility-tutorial?style=social)](https://github.com/jesperdramsch/ml-for-science-reproducibility-tutorial)

A collection of "easy wins" to make machine learning in research reproducible.  

This books focuses on basics that work. 
Getting you 90% of the way to top-tier reproducibility.

Every scientific conference has seen a massive uptick in applications that use some type of machine learning. Whether it‚Äôs a linear regression using scikit-learn, a transformer from Hugging Face, or a custom convolutional neural network in Jax, the breadth of applications is as vast as the quality of contributions.

This tutorial aims to provide easy ways to increase the quality of scientific contributions that use machine learning methods. The reproducible aspect will make it easy for fellow researchers to use and iterate on a publication, increasing citations of published work. The use of appropriate validation techniques and increase in code quality accelerates the review process during publication and avoids possible rejection due to deficiencies in the methodology. Making models, code and possibly data available increases the visibility of work and enables easier collaboration on future work.

This work to make machine learning applications reproducible has an outsized impact compared to the limited additional work that is required using existing Python libraries.



:::

::::

::::{grid} 1 1 2 3
:class-container: text-center
:gutter: 3

:::{grid-item-card}
:link: tutorial/evaluation
:link-type: doc
:class-header: bg-light

Model Evaluation ü§ñ
^^^

Avoid overfitting and ensure results work on future data reliably.

:::

:::{grid-item-card}
:link: tutorial/benchmarking
:link-type: doc
:class-header: bg-light

Benchmarking ü™ë
^^^

Compare your results to other solutions on standardized datasets and metrics.

:::

:::{grid-item-card}
:link: tutorial/sharing
:link-type: doc
:class-header: bg-light

Model Sharing ü§ù
^^^

Export and share models to collaborate and gain citations.
:::

:::{grid-item-card}
:link: tutorial/testing
:link-type: doc
:class-header: bg-light

Testing üß™
^^^

Catch code errors early and test that data is treated correctly.
:::

:::{grid-item-card}
:link: tutorial/interpretability
:link-type: doc
:class-header: bg-light

Interpretability ‚ö°
^^^

Communicate results and inspect models to avoid spurious correlations.
:::

:::{grid-item-card}
:link: tutorial/ablation
:link-type: doc
:class-header: bg-light

Ablation Studies üî™
^^^

Model building is iterative, so explore which parts actually matter.
:::

::::

This book is organized into these major sections:

- **Motivation** to expand on how the following sections aide in increasing citations, easing review, and fostering collaboration.
- **Front Matter** that goes into the installation and data.
- **How To** with notebooks and additional resources on the sections to improve research artifacts.
- **Talks & Workshop** that showcase presentations around this material.

Overall, this tutorial is aimed at applied scientists that want to explore machine learning solutions for their problems.

This tutorial focuses on a collection of ‚Äúeasy wins‚Äù that scientists can implement in their research to avoid catastrophic failures and increase reproducibility with all its benefits.
