{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2700d882",
   "metadata": {},
   "source": [
    "# Getting to know the data\n",
    "\n",
    "Understanding the data is a foundational step in any machine learning project and is crucial for achieving reproducibility in research. \n",
    "\n",
    "Comprehending the dataset lets us make informed decisions at every stage of the project, from preprocessing to model selection and evaluation.\n",
    "\n",
    "One of the primary reasons why getting to know the data is essential is its direct impact on the reliability and generalizability of the machine learning models. We can identify potential biases, anomalies, or inconsistencies that may affect model performance by exploring the data. \n",
    "\n",
    "This understanding enables us to apply appropriate preprocessing techniques, such as handling missing values, addressing class imbalances, or feature normalisation, to ensure that the model learns meaningful patterns from the data.\n",
    "\n",
    "Furthermore, understanding the data allows researchers to select appropriate evaluation metrics that align with the specific objectives and characteristics of the dataset. \n",
    "\n",
    "By choosing metrics that capture the nuances of the problem domain, researchers can accurately assess the performance of their models and make informed decisions about their suitability for real-world applications.\n",
    "\n",
    "Moreover, gaining insights into the data can guide us as researchers in selecting the most appropriate algorithms and architectures for these tasks. Understanding the distribution and relationships within the data allows us to choose well-suited models to capture complex patterns and make accurate predictions.\n",
    "\n",
    "Beyond improving the performance of individual models, understanding the data fosters transparency and reproducibility in research. By documenting the dataset's characteristics and the rationale behind preprocessing decisions, researchers enable others to replicate their experiments and validate their findings. \n",
    "\n",
    "This transparency enhances the credibility of research outcomes and facilitates collaboration and knowledge sharing within the scientific community.\n",
    "\n",
    "This tutorial uses the [Palmer Penguins dataset](https://allisonhorst.github.io/palmerpenguins/). Data were collected and made available by [Dr. Kristen Gorman](https://www.uaf.edu/cfos/people/faculty/detail/kristen-gorman.php) and the [Palmer Station, Antarctica LTER](https://pallter.marine.rutgers.edu/), a member of the [Long Term Ecological Research Network](https://lternet.edu/).\n",
    "\n",
    "Let's dive into some quick exploration of the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54158e1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T01:42:07.155662Z",
     "iopub.status.busy": "2022-12-13T01:42:07.155163Z",
     "iopub.status.idle": "2022-12-13T01:42:07.166664Z",
     "shell.execute_reply": "2022-12-13T01:42:07.166664Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DATA_FOLDER = Path(\"..\", \"..\") / \"data\"\n",
    "DATA_FILEPATH = DATA_FOLDER / \"penguins.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8163eb",
   "metadata": {},
   "source": [
    "We'll use the `pandas` library to load an pre-process the data. It has quite a few convenience functions like loading CSVs or dropping columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36b24fd4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T01:42:07.169664Z",
     "iopub.status.busy": "2022-12-13T01:42:07.169165Z",
     "iopub.status.idle": "2022-12-13T01:42:07.570293Z",
     "shell.execute_reply": "2022-12-13T01:42:07.569793Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01e133b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T01:42:07.573794Z",
     "iopub.status.busy": "2022-12-13T01:42:07.573293Z",
     "iopub.status.idle": "2022-12-13T01:42:07.601299Z",
     "shell.execute_reply": "2022-12-13T01:42:07.600798Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>studyName</th>\n",
       "      <th>Sample Number</th>\n",
       "      <th>Species</th>\n",
       "      <th>Region</th>\n",
       "      <th>Island</th>\n",
       "      <th>Stage</th>\n",
       "      <th>Individual ID</th>\n",
       "      <th>Clutch Completion</th>\n",
       "      <th>Date Egg</th>\n",
       "      <th>Culmen Length (mm)</th>\n",
       "      <th>Culmen Depth (mm)</th>\n",
       "      <th>Flipper Length (mm)</th>\n",
       "      <th>Body Mass (g)</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Delta 15 N (o/oo)</th>\n",
       "      <th>Delta 13 C (o/oo)</th>\n",
       "      <th>Comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PAL0708</td>\n",
       "      <td>1</td>\n",
       "      <td>Adelie Penguin (Pygoscelis adeliae)</td>\n",
       "      <td>Anvers</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>Adult, 1 Egg Stage</td>\n",
       "      <td>N1A1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2007-11-11</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>MALE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not enough blood for isotopes.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PAL0708</td>\n",
       "      <td>2</td>\n",
       "      <td>Adelie Penguin (Pygoscelis adeliae)</td>\n",
       "      <td>Anvers</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>Adult, 1 Egg Stage</td>\n",
       "      <td>N1A2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2007-11-11</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>8.94956</td>\n",
       "      <td>-24.69454</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PAL0708</td>\n",
       "      <td>3</td>\n",
       "      <td>Adelie Penguin (Pygoscelis adeliae)</td>\n",
       "      <td>Anvers</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>Adult, 1 Egg Stage</td>\n",
       "      <td>N2A1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2007-11-16</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>8.36821</td>\n",
       "      <td>-25.33302</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PAL0708</td>\n",
       "      <td>4</td>\n",
       "      <td>Adelie Penguin (Pygoscelis adeliae)</td>\n",
       "      <td>Anvers</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>Adult, 1 Egg Stage</td>\n",
       "      <td>N2A2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2007-11-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adult not sampled.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PAL0708</td>\n",
       "      <td>5</td>\n",
       "      <td>Adelie Penguin (Pygoscelis adeliae)</td>\n",
       "      <td>Anvers</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>Adult, 1 Egg Stage</td>\n",
       "      <td>N3A1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2007-11-16</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>8.76651</td>\n",
       "      <td>-25.32426</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  studyName  Sample Number                              Species  Region  \\\n",
       "0   PAL0708              1  Adelie Penguin (Pygoscelis adeliae)  Anvers   \n",
       "1   PAL0708              2  Adelie Penguin (Pygoscelis adeliae)  Anvers   \n",
       "2   PAL0708              3  Adelie Penguin (Pygoscelis adeliae)  Anvers   \n",
       "3   PAL0708              4  Adelie Penguin (Pygoscelis adeliae)  Anvers   \n",
       "4   PAL0708              5  Adelie Penguin (Pygoscelis adeliae)  Anvers   \n",
       "\n",
       "      Island               Stage Individual ID Clutch Completion    Date Egg  \\\n",
       "0  Torgersen  Adult, 1 Egg Stage          N1A1               Yes  2007-11-11   \n",
       "1  Torgersen  Adult, 1 Egg Stage          N1A2               Yes  2007-11-11   \n",
       "2  Torgersen  Adult, 1 Egg Stage          N2A1               Yes  2007-11-16   \n",
       "3  Torgersen  Adult, 1 Egg Stage          N2A2               Yes  2007-11-16   \n",
       "4  Torgersen  Adult, 1 Egg Stage          N3A1               Yes  2007-11-16   \n",
       "\n",
       "   Culmen Length (mm)  Culmen Depth (mm)  Flipper Length (mm)  Body Mass (g)  \\\n",
       "0                39.1               18.7                181.0         3750.0   \n",
       "1                39.5               17.4                186.0         3800.0   \n",
       "2                40.3               18.0                195.0         3250.0   \n",
       "3                 NaN                NaN                  NaN            NaN   \n",
       "4                36.7               19.3                193.0         3450.0   \n",
       "\n",
       "      Sex  Delta 15 N (o/oo)  Delta 13 C (o/oo)  \\\n",
       "0    MALE                NaN                NaN   \n",
       "1  FEMALE            8.94956          -24.69454   \n",
       "2  FEMALE            8.36821          -25.33302   \n",
       "3     NaN                NaN                NaN   \n",
       "4  FEMALE            8.76651          -25.32426   \n",
       "\n",
       "                         Comments  \n",
       "0  Not enough blood for isotopes.  \n",
       "1                             NaN  \n",
       "2                             NaN  \n",
       "3              Adult not sampled.  \n",
       "4                             NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penguins_raw = pd.read_csv(DATA_FILEPATH)\n",
    "penguins_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8b426b",
   "metadata": {},
   "source": [
    "We can see that this dataset has a lot more potential than your usual \"toy dataset\". We get the full provenance of this data including the study a penguin was measured in, where it lives, and even comments by the researchers collecting the data!\n",
    "\n",
    "And honestly, this looks like a lot. Some of these variables might actually leak information, like the location or study number telling us what penguin colony was sampled.\n",
    "\n",
    "Let's reduce this to some numerical columns `Culmen Length (mm)`, `Culmen Depth (mm)`, `Flipper Length (mm)`, then `Sex` as a categorical value in case penguins exhibit [sexual dimorphism](https://en.wikipedia.org/wiki/Sexual_dimorphism) and the `species` as our target column to make it easier for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93eedeb8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T01:42:07.603799Z",
     "iopub.status.busy": "2022-12-13T01:42:07.603799Z",
     "iopub.status.idle": "2022-12-13T01:42:07.616802Z",
     "shell.execute_reply": "2022-12-13T01:42:07.616302Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Culmen Length (mm)</th>\n",
       "      <th>Culmen Depth (mm)</th>\n",
       "      <th>Flipper Length (mm)</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>MALE</td>\n",
       "      <td>Adelie Penguin (Pygoscelis adeliae)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>Adelie Penguin (Pygoscelis adeliae)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>Adelie Penguin (Pygoscelis adeliae)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adelie Penguin (Pygoscelis adeliae)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>Adelie Penguin (Pygoscelis adeliae)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>55.8</td>\n",
       "      <td>19.8</td>\n",
       "      <td>207.0</td>\n",
       "      <td>MALE</td>\n",
       "      <td>Chinstrap penguin (Pygoscelis antarctica)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>43.5</td>\n",
       "      <td>18.1</td>\n",
       "      <td>202.0</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>Chinstrap penguin (Pygoscelis antarctica)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>49.6</td>\n",
       "      <td>18.2</td>\n",
       "      <td>193.0</td>\n",
       "      <td>MALE</td>\n",
       "      <td>Chinstrap penguin (Pygoscelis antarctica)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>50.8</td>\n",
       "      <td>19.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>MALE</td>\n",
       "      <td>Chinstrap penguin (Pygoscelis antarctica)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>50.2</td>\n",
       "      <td>18.7</td>\n",
       "      <td>198.0</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>Chinstrap penguin (Pygoscelis antarctica)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>344 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Culmen Length (mm)  Culmen Depth (mm)  Flipper Length (mm)     Sex  \\\n",
       "0                  39.1               18.7                181.0    MALE   \n",
       "1                  39.5               17.4                186.0  FEMALE   \n",
       "2                  40.3               18.0                195.0  FEMALE   \n",
       "3                   NaN                NaN                  NaN     NaN   \n",
       "4                  36.7               19.3                193.0  FEMALE   \n",
       "..                  ...                ...                  ...     ...   \n",
       "339                55.8               19.8                207.0    MALE   \n",
       "340                43.5               18.1                202.0  FEMALE   \n",
       "341                49.6               18.2                193.0    MALE   \n",
       "342                50.8               19.0                210.0    MALE   \n",
       "343                50.2               18.7                198.0  FEMALE   \n",
       "\n",
       "                                       Species  \n",
       "0          Adelie Penguin (Pygoscelis adeliae)  \n",
       "1          Adelie Penguin (Pygoscelis adeliae)  \n",
       "2          Adelie Penguin (Pygoscelis adeliae)  \n",
       "3          Adelie Penguin (Pygoscelis adeliae)  \n",
       "4          Adelie Penguin (Pygoscelis adeliae)  \n",
       "..                                         ...  \n",
       "339  Chinstrap penguin (Pygoscelis antarctica)  \n",
       "340  Chinstrap penguin (Pygoscelis antarctica)  \n",
       "341  Chinstrap penguin (Pygoscelis antarctica)  \n",
       "342  Chinstrap penguin (Pygoscelis antarctica)  \n",
       "343  Chinstrap penguin (Pygoscelis antarctica)  \n",
       "\n",
       "[344 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features = [\"Culmen Length (mm)\", \"Culmen Depth (mm)\", \"Flipper Length (mm)\"]\n",
    "cat_features = [\"Sex\"]\n",
    "features = num_features + cat_features\n",
    "target = [\"Species\"]\n",
    "penguins = penguins_raw[features+target]\n",
    "penguins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7bc066",
   "metadata": {},
   "source": [
    "Much easier to deal with for a non-expert in Penguin studies!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a9fcdc",
   "metadata": {},
   "source": [
    "## Data Visualization\n",
    "\n",
    "Data visualization is indispensable for effective data exploration in machine learning research. \n",
    "\n",
    "We can quickly grasp the datasets' distribution, relationships, and anomalies through visual representations like scatter plots, histograms, and box plots. These visualizations provide invaluable insights into the underlying structure of the data, enabling researchers to identify patterns, trends, and outliers that may influence model performance. \n",
    "\n",
    "Moreover, visualizations facilitate collaboration and communication among team members, as they provide intuitive ways to convey complex insights and findings. \n",
    "\n",
    "In essence, data visualization is a cornerstone of data exploration, enhancing the reproducibility and reliability of machine learning research by enabling researchers to gain a deeper understanding of their datasets.\n",
    "\n",
    "For this visualization we'll use `seaborn` which is a statistical plotting library that makes our job much easier than the more granular `matplotlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8378dc03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T01:42:07.619802Z",
     "iopub.status.busy": "2022-12-13T01:42:07.619302Z",
     "iopub.status.idle": "2022-12-13T01:42:07.787334Z",
     "shell.execute_reply": "2022-12-13T01:42:07.786833Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      3\u001b[0m pairplot_figure \u001b[38;5;241m=\u001b[39m sns\u001b[38;5;241m.\u001b[39mpairplot(penguins, hue\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpecies\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "pairplot_figure = sns.pairplot(penguins, hue=\"Species\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d5fc44",
   "metadata": {},
   "source": [
    "Looks like we're getting some good separation of the clusters already!\n",
    "\n",
    "This promises to be a good dataset for fairly simple machine learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d406bd6f",
   "metadata": {},
   "source": [
    "## Data cleaning\n",
    "\n",
    "That means we can probably do some cleaning and get ready to build some good machine learning models.\n",
    "\n",
    "Dropping NaNs, or missing values, during the data cleaning process is the most basic form of cleaning data. Some machine learning algorithms can actually process NaNs, which is a great way to deal with missing data, but in our case we're choosing the simplest way. Don't take this as the best practice though!\n",
    "\n",
    "By removing rows or columns containing NaNs, researchers can prevent these issues and ensure that their models learn from complete and consistent data. While imputation techniques exist to fill in missing values, dropping NaNs is often preferred when the proportion of missing values is small relative to the dataset size or when imputation could introduce inaccuracies.\n",
    "\n",
    "Sometimes we can even gain information from NaNs, when they're not \"missing at random\". Then we can actually pre-process the data by adding a boolean feature that encodes the \"missingness\" of a variable and use mean imputation on the data column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791232d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T01:42:07.789834Z",
     "iopub.status.busy": "2022-12-13T01:42:07.789834Z",
     "iopub.status.idle": "2022-12-13T01:42:07.802336Z",
     "shell.execute_reply": "2022-12-13T01:42:07.802336Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Culmen Length (mm)</th>\n",
       "      <th>Culmen Depth (mm)</th>\n",
       "      <th>Flipper Length (mm)</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>MALE</td>\n",
       "      <td>Adelie Penguin (Pygoscelis adeliae)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>Adelie Penguin (Pygoscelis adeliae)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>Adelie Penguin (Pygoscelis adeliae)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>Adelie Penguin (Pygoscelis adeliae)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>39.3</td>\n",
       "      <td>20.6</td>\n",
       "      <td>190.0</td>\n",
       "      <td>MALE</td>\n",
       "      <td>Adelie Penguin (Pygoscelis adeliae)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>55.8</td>\n",
       "      <td>19.8</td>\n",
       "      <td>207.0</td>\n",
       "      <td>MALE</td>\n",
       "      <td>Chinstrap penguin (Pygoscelis antarctica)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>43.5</td>\n",
       "      <td>18.1</td>\n",
       "      <td>202.0</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>Chinstrap penguin (Pygoscelis antarctica)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>49.6</td>\n",
       "      <td>18.2</td>\n",
       "      <td>193.0</td>\n",
       "      <td>MALE</td>\n",
       "      <td>Chinstrap penguin (Pygoscelis antarctica)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>50.8</td>\n",
       "      <td>19.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>MALE</td>\n",
       "      <td>Chinstrap penguin (Pygoscelis antarctica)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>50.2</td>\n",
       "      <td>18.7</td>\n",
       "      <td>198.0</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>Chinstrap penguin (Pygoscelis antarctica)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>334 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Culmen Length (mm)  Culmen Depth (mm)  Flipper Length (mm)     Sex  \\\n",
       "0                  39.1               18.7                181.0    MALE   \n",
       "1                  39.5               17.4                186.0  FEMALE   \n",
       "2                  40.3               18.0                195.0  FEMALE   \n",
       "4                  36.7               19.3                193.0  FEMALE   \n",
       "5                  39.3               20.6                190.0    MALE   \n",
       "..                  ...                ...                  ...     ...   \n",
       "339                55.8               19.8                207.0    MALE   \n",
       "340                43.5               18.1                202.0  FEMALE   \n",
       "341                49.6               18.2                193.0    MALE   \n",
       "342                50.8               19.0                210.0    MALE   \n",
       "343                50.2               18.7                198.0  FEMALE   \n",
       "\n",
       "                                       Species  \n",
       "0          Adelie Penguin (Pygoscelis adeliae)  \n",
       "1          Adelie Penguin (Pygoscelis adeliae)  \n",
       "2          Adelie Penguin (Pygoscelis adeliae)  \n",
       "4          Adelie Penguin (Pygoscelis adeliae)  \n",
       "5          Adelie Penguin (Pygoscelis adeliae)  \n",
       "..                                         ...  \n",
       "339  Chinstrap penguin (Pygoscelis antarctica)  \n",
       "340  Chinstrap penguin (Pygoscelis antarctica)  \n",
       "341  Chinstrap penguin (Pygoscelis antarctica)  \n",
       "342  Chinstrap penguin (Pygoscelis antarctica)  \n",
       "343  Chinstrap penguin (Pygoscelis antarctica)  \n",
       "\n",
       "[334 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penguins = penguins.dropna(axis='rows')\n",
    "penguins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44aaf953",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T01:42:07.805337Z",
     "iopub.status.busy": "2022-12-13T01:42:07.804837Z",
     "iopub.status.idle": "2022-12-13T01:42:07.818339Z",
     "shell.execute_reply": "2022-12-13T01:42:07.817839Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_CLEAN_FILEPATH = DATA_FOLDER / \"penguins_clean.csv\"\n",
    "\n",
    "penguins.to_csv(DATA_CLEAN_FILEPATH, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8beada8",
   "metadata": {},
   "source": [
    "Not too bad it looks like we lost ten rows. That's manageable, it's a toy dataset after all.\n",
    "\n",
    "So let's build a small model to classify penguins!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d195ee41",
   "metadata": {},
   "source": [
    "## Machine Learning\n",
    "\n",
    "First, it's essential to split the data into separate sets for training and testing purposes. \n",
    "\n",
    "This split enables us to evaluate the performance of our machine learning model effectively. By training the model on a portion of the data and testing it on unseen data, we can assess whether the model has learned generalizable patterns or has simply memorized the training examples.\n",
    "\n",
    "When a model that fails to generalize to unseen data this is known as overfitting. Overfitting is a phenomenon where the model performs well on the training data but fails on non-training data. Overfitting leads to poor performance and unreliable predictions in real-world scenarios. \n",
    "\n",
    "Therefore, by splitting the data, we can detect and mitigate overfitting, ensuring that our model learns meaningful patterns that generalize to unseen data.\n",
    "\n",
    "We'll choose 70% of the data as training data here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "210ae85e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T01:42:07.820839Z",
     "iopub.status.busy": "2022-12-13T01:42:07.820839Z",
     "iopub.status.idle": "2022-12-13T01:42:07.849350Z",
     "shell.execute_reply": "2022-12-13T01:42:07.848850Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      3\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(penguins[features], penguins[target], train_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m.7\u001b[39m)\n\u001b[0;32m      4\u001b[0m X_train\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(penguins[features], penguins[target], train_size=.7)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94df8062",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T01:42:07.852351Z",
     "iopub.status.busy": "2022-12-13T01:42:07.851851Z",
     "iopub.status.idle": "2022-12-13T01:42:07.880222Z",
     "shell.execute_reply": "2022-12-13T01:42:07.879722Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43my_train\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_train' is not defined"
     ]
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d6b50d",
   "metadata": {},
   "source": [
    "Now we can build a machine learning model.\n",
    "\n",
    "Here we'll use the scikit-learn pipeline model. \n",
    "This makes it really easy for us to train prepocessors and models on the training data alone and cleanly apply to the test data set without leakage.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ded576",
   "metadata": {},
   "source": [
    "### Pre-processing\n",
    "\n",
    "Pre-processing data is the next critical step in preparing it for machine learning models, and the scikit-learn library offers powerful tools like `StandardScaler` and `OneHotEncoder` to facilitate this process. \n",
    "\n",
    "The `StandardScaler` is commonly used to standardize features by removing the mean and scaling them to unit variance, ensuring that each feature contributes equally to the model's performance. This transformation is particularly beneficial for algorithms sensitive to feature scaling, such as support vector machines and k-nearest neighbours. \n",
    "\n",
    "On the other hand, OneHotEncoder is instrumental in handling categorical variables by converting them into a binary representation, where each category becomes a binary feature. This transformation prevents the model from interpreting categorical variables as ordinal, e.g. category `1` is \"stronger\" than category `0`, and ensures that all categories are treated equally.\n",
    "\n",
    "Together, these pre-processing techniques help enhance the performance and robustness of machine learning models, ready to be fed into the model for training and evaluation.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Tip:</b> In science, any type of feature selection, scaling, basically anything you do to the data, needs to be done <strong>after</strong> a split into training and test set.<br>Statistically and scientifically valid results come from proper treatment of our data. Unfortunately, we can overfit manually if we don't split out a test set before pre-processing.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c4e2c77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T01:42:07.883223Z",
     "iopub.status.busy": "2022-12-13T01:42:07.882723Z",
     "iopub.status.idle": "2022-12-13T01:42:07.911231Z",
     "shell.execute_reply": "2022-12-13T01:42:07.910731Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler, OneHotEncoder\n\u001b[0;32m      3\u001b[0m num_transformer \u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[0;32m      4\u001b[0m cat_transformer \u001b[38;5;241m=\u001b[39m OneHotEncoder(handle_unknown\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "num_transformer = StandardScaler()\n",
    "cat_transformer = OneHotEncoder(handle_unknown='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1f3d28",
   "metadata": {},
   "source": [
    "The `ColumnTransformer` is a neat tool that can apply your preprocessing steps to the right columns in your dataset. \n",
    "\n",
    "This transformer is pretty efficient because it allows us to target individual subsets of data for transformation, ensuring that preprocessing techniques are applied only where necessary. \n",
    "\n",
    "Moreover, leveraging a Pipeline instead of a standalone `StandardScaler` or `ColumnTransformer` offers even greater flexibility, enabling the integration of more intricate preprocessing workflows, which we'll see further below. This versatility is particularly valuable when working on complex machine learning tasks that demand comprehensive preprocessing strategies beyond the scope of basic projects, enabling researchers to unleash the full potential of their data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a797998",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T01:42:07.914232Z",
     "iopub.status.busy": "2022-12-13T01:42:07.913731Z",
     "iopub.status.idle": "2022-12-13T01:42:07.942236Z",
     "shell.execute_reply": "2022-12-13T01:42:07.941736Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompose\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ColumnTransformer\n\u001b[0;32m      3\u001b[0m preprocessor \u001b[38;5;241m=\u001b[39m ColumnTransformer(transformers\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m      4\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum\u001b[39m\u001b[38;5;124m'\u001b[39m, num_transformer, num_features),\n\u001b[0;32m      5\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcat\u001b[39m\u001b[38;5;124m'\u001b[39m, cat_transformer, cat_features)\n\u001b[0;32m      6\u001b[0m ])\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', num_transformer, num_features),\n",
    "    ('cat', cat_transformer, cat_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31c303f",
   "metadata": {},
   "source": [
    "Ok now we'll build a reproducible `Pipeline` including a support-vector machine as the classifier!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3efeca5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T01:42:07.945237Z",
     "iopub.status.busy": "2022-12-13T01:42:07.945237Z",
     "iopub.status.idle": "2022-12-13T01:42:07.973244Z",
     "shell.execute_reply": "2022-12-13T01:42:07.972743Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Pipeline\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msvm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SVC\n\u001b[0;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m Pipeline(steps\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m      5\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreprocessor\u001b[39m\u001b[38;5;124m'\u001b[39m, preprocessor),\n\u001b[0;32m      6\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassifier\u001b[39m\u001b[38;5;124m'\u001b[39m, SVC()),\n\u001b[0;32m      7\u001b[0m ])\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', SVC()),\n",
    "])\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac533079",
   "metadata": {},
   "source": [
    "We can see a nice model representation here.\n",
    "\n",
    "You can click on the different modules that will tell you which arguments were passed into the pipeline. In our case, how we handle unknown values in the OneHotEncoder.\n",
    "\n",
    "The `Pipeline` offers a convenient solution to prevent unintentional leakage of information from test data during preprocessing. By encapsulating preprocessing steps within a pipeline, each transformation is applied sequentially and independently to the data, ensuring that normalizers and other preprocessing techniques are fitted solely on the training data. \n",
    "\n",
    "This prevents the inadvertent fitting of preprocessors to the test data, mitigating the risk of information leakage and preserving the integrity of the evaluation process. One way to avoid accidents in our research!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f8a49a",
   "metadata": {},
   "source": [
    "### Model Training\n",
    "\n",
    "Now it's time to fit our Support-Vector Machine to our training data.\n",
    "\n",
    "This process involves training the model on the provided training data to learn patterns and relationships within the features and their corresponding labels. During the fitting process, the model adjusts its parameters to minimize the difference between its predictions and the actual target values. \n",
    "\n",
    "The `.fit()` method encapsulates this training process, allowing the model to learn from the training data and prepare for subsequent evaluation and prediction tasks. \n",
    "\n",
    "(And it's all in the `Pipeline`, which makes sure our pre-processors get fitted to the same exact data!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8d0a2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T01:42:07.976745Z",
     "iopub.status.busy": "2022-12-13T01:42:07.976244Z",
     "iopub.status.idle": "2022-12-13T01:42:08.003898Z",
     "shell.execute_reply": "2022-12-13T01:42:08.003398Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mfit(X_train, y_train[target[\u001b[38;5;241m0\u001b[39m]])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train[target[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99d171d",
   "metadata": {},
   "source": [
    "We can see that we get a decent score on the training data.\n",
    "\n",
    "This metric only tells us how well the model can perform on the data it has seen, we don't know anything about generalization and actual \"learning\" yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc341232",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T01:42:08.006398Z",
     "iopub.status.busy": "2022-12-13T01:42:08.006398Z",
     "iopub.status.idle": "2022-12-13T01:42:08.034833Z",
     "shell.execute_reply": "2022-12-13T01:42:08.034332Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mscore(X_train, y_train)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca68a355",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "To evaluate how well our model learned, we check the model against the test data one final time.\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Tip:</b> It is possible to manually overfit a model to the test set, by tweaking the pipelines based on the test score.<br>This invalidates scientific results and must be avoided. If you need to manually tweak the model, use a three-way `train-val-test` split.<br>Only evaluate on the test set once!</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f28497a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T01:42:08.037333Z",
     "iopub.status.busy": "2022-12-13T01:42:08.037333Z",
     "iopub.status.idle": "2022-12-13T01:42:08.065910Z",
     "shell.execute_reply": "2022-12-13T01:42:08.065410Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mscore(X_test, y_test)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c21141",
   "metadata": {},
   "source": [
    "That's an extraordinary score! \n",
    "\n",
    "We can predict our penguins with 100%, so let's evaluate these models in the following pages!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('pydata-global-2022-ml-repro')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "d7369b48cea8bb1af6d88d25f2646d14ea11b68d7457d74f06fbf0d68480668d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
