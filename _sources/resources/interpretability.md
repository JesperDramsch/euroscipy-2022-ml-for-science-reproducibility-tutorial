# Interpretability Resources

Machine learning interpretability has a fancier alias, called [Explainable AI (XAI)](https://en.wikipedia.org/wiki/Explainable_artificial_intelligence). You can read the book{cite:t}`molnar2022` for a deep dive [into ML interpretability](https://christophm.github.io/interpretable-ml-book/).

There are a few tools available, namely:

- [Scikit-learn Inspection](https://scikit-learn.org/stable/inspection.html) {cite:p}`scikit-learn`
- [SHAP](https://github.com/slundberg/shap) (not in the best state currently, but beautiful if it works) {cite:p}`shap`
- [Alibi](https://github.com/SeldonIO/alibi) {cite:p}`alibi`
- [Captum](https://github.com/pytorch/captum) for Pytorch {cite:p}`captum`
- [Deepviz Toolbox](https://github.com/yosinski/deep-visualization-toolbox) {cite:p}`deepvis`

## Bibliography

```{bibliography}
:filter: docname in docnames
```